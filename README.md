# Predi√ß√£o de Diabetes mellitus utilizando Modelos de Aprendizado de M√°quina

Este projeto investiga o uso de algoritmos de aprendizado de m√°quina para prever o risco de diabetes com base em dados cl√≠nicos e populacionais. O trabalho foi desenvolvido por estudantes dos departamentos de **Estat√≠stica (DEs)** e **Computa√ß√£o (DC)** da **Universidade Federal de S√£o Carlos (UFSCar)**.

O diagn√≥stico precoce √© essencial para evitar complica√ß√µes graves, como doen√ßas cardiovasculares e insufici√™ncia renal. Este estudo utiliza t√©cnicas de aprendizado de m√°quina (ML) para identificar padr√µes em vari√°veis como glicose, IMC e idade, oferecendo uma ferramenta de triagem acess√≠vel.

---

## üìä Vis√£o Geral dos Datasets

O estudo avalia a robustez dos modelos em dois cen√°rios distintos:

- **Indian Pima Diabetes Dataset**: Cont√©m 768 registros de pacientes com 8 vari√°veis cl√≠nicas, focado em prever a ocorr√™ncia de diabetes com base em dados laboratoriais.
- **Vigitel (2023)**: Extra√≠do do sistema de vigil√¢ncia do Minist√©rio da Sa√∫de do Brasil, cont√©m 21.690 registros com foco em fatores de risco populacionais.

---

## ‚öôÔ∏è Metodologia Experimental

A pipeline foi estruturada para garantir o rigor estat√≠stico e a replicabilidade dos resultados:

### 1. Pr√©-processamento e Limpeza

- **Tratamento de Dados (Pima)**: No dataset Pima, valores `0` em vari√°veis como Insulina foram tratados como dados faltantes e imputados via **mediana**, garantindo robustez contra *outliers*.
- **Tratamento de Dados (Vigitel)**: Valores ausentes foram preenchidos com a m√©dia das colunas.
- **Normaliza√ß√£o**: Aplica√ß√£o de `StandardScaler` para garantir que modelos baseados em dist√¢ncia (SVM) e gradiente (Redes Neurais) n√£o fossem enviesados pela escala das vari√°veis.

### 2. Divis√£o e Treinamento

- **Divis√£o Estratificada**: 80% para treino e 20% para teste.
- **Otimiza√ß√£o**: Uso do `RandomizedSearchCV` para ajuste de hiperpar√¢metros.

---

## üß† Modelos Avaliados

1. **Regress√£o Log√≠stica**  
2. **Random Forest**  
3. **SVM (Support Vector Machine)**  
4. **Rede Neural (MLP)**  

---

## üìà An√°lise T√©cnica de Resultados

### Comparativo de M√©tricas (Dataset Pima)

![Desempenho dos Modelos](figures/Figure_1.png)

*Comparativo de Acur√°cia, Precis√£o, Recall e F1-Score.*

---

### Import√¢ncia das Vari√°veis

![Import√¢ncia das Vari√°veis](figures/Figure_6.png)

*Glicose e IMC consolidam-se como os principais preditores estat√≠sticos.*

---

### Matrizes de Confus√£o

| **Logistic Regression** | **Random Forest** |
| :---: | :---: |
| ![](figures/Figure_2.png) | ![](figures/Figure_3.png) |
| **SVM** | **Neural Network** |
| ![](figures/Figure_4.png) | ![](figures/Figure_5.png) |

---

### Resumo dos Resultados

- **Indian Pima**: O **Random Forest** apresentou o melhor **Recall** ap√≥s o ajuste de hiperpar√¢metros, sendo o modelo mais seguro para triagem (minimiza√ß√£o de falsos negativos).  
- **Vigitel**: A alta acur√°cia da Regress√£o Log√≠stica esconde um desafio de **desbalanceamento de classes**, onde o modelo tende a favorecer a classe majorit√°ria.
- **Geral**: Modelos n√£o-lineares como Random Forest mostraram maior **resili√™ncia** a amostras reduzidas e dados ruidosos.

---

## üöÄ Como Executar

1. Instale as depend√™ncias:

```bash
pip install -r requirements.txt
